\relax 
\citation{rasmussen2000infinite}
\citation{teh2006hierarchical}
\citation{paisley2011discrete}
\citation{beal2001infinite}
\citation{teh2006hierarchical}
\citation{blei2011distance}
\citation{teh2006hierarchical}
\citation{gilks1992adaptive}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}A Hierarchical Dirichlet Process Hidden Markov Model With ``Local'' Transitions (HDP-HMM-LT)}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{teh2006hierarchical}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Transition Dynamics in the HDP-HMM}{2}}
\newlabel{sec:transition-dynamics}{{1.1}{2}}
\newlabel{eq:1}{{1.3}{2}}
\newlabel{eq:4}{{1.4}{2}}
\citation{ferguson1973bayesian}
\newlabel{eq:5}{{1.5}{3}}
\newlabel{eq:6}{{1.6}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}An HDP-HMM With Local Transitions}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}A Normalized Gamma Process representation of the HDP-HMM}{4}}
\newlabel{sec:normalized-gamma}{{1.2.1}{4}}
\newlabel{eq:17}{{1.7}{4}}
\newlabel{eq:18}{{1.8}{4}}
\newlabel{eq:16}{{1.9}{4}}
\newlabel{eq:19}{{1.10}{4}}
\newlabel{eq:20}{{1.11}{4}}
\newlabel{eq:21}{{1.12}{4}}
\newlabel{eq:22}{{1.13}{4}}
\newlabel{eq:23}{{1.15}{4}}
\newlabel{eq:50}{{1.16}{4}}
\newlabel{eq:24}{{1.17}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Promoting ``Local" Transitions}{5}}
\newlabel{sec:prom-local-trans}{{1.2.2}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}The HDP-HMM-LT as a continuous-time Markov Jump Process with ``failed'' jumps}{6}}
\newlabel{sec:dist-based-filt}{{1.2.3}{6}}
\newlabel{eq:beta}{{1.24}{6}}
\newlabel{eq:51}{{1.27}{6}}
\newlabel{eq:52}{{1.28}{7}}
\newlabel{eq:53}{{1.29}{7}}
\newlabel{eq:56}{{1.30}{7}}
\newlabel{eq:60}{{1.34}{7}}
\citation{johnson2013bayesian}
\newlabel{eq:54}{{1.35}{8}}
\newlabel{eq:joint-likelihood}{{1.40}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}An HDP-HSMM-LT modification}{8}}
\newlabel{sec:an-hsmm-modification}{{1.2.4}{8}}
\newlabel{eq:95}{{1.41}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.5}Summary}{9}}
\newlabel{sec:model-summary}{{1.2.5}{9}}
\newlabel{eq:96}{{1.43}{9}}
\newlabel{eq:likelihood}{{1.49}{9}}
\newlabel{eq:97}{{1.50}{9}}
\newlabel{eq:98}{{1.52}{9}}
\newlabel{eq:likelihood-hsmm}{{1.53}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Inference}{9}}
\newlabel{sec:inference}{{1.3}{9}}
\newlabel{eq:28}{{1.54}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Sampling $\bm  {\pi }$, $\bm  {\beta }$, $\alpha $ and $\gamma $}{10}}
\newlabel{sec:sampling-pi}{{1.3.1}{10}}
\newlabel{eq:46}{{1.55}{10}}
\@writefile{toc}{\contentsline {subsubsection}{Sampling $\bm  {\pi }$}{10}}
\newlabel{eq:47}{{1.56}{10}}
\newlabel{eq:61}{{1.57}{10}}
\citation{teh2006hierarchical}
\newlabel{eq:24}{{1.58}{11}}
\newlabel{eq:25}{{1.59}{11}}
\@writefile{toc}{\contentsline {subsubsection}{Sampling $\bm  {\beta }$}{11}}
\newlabel{sec:sampling-bbeta}{{1.3.1}{11}}
\newlabel{eq:62}{{1.60}{11}}
\newlabel{eq:31}{{1.66}{12}}
\newlabel{eq:32}{{1.67}{12}}
\newlabel{eq:33}{{1.68}{12}}
\newlabel{eq:34}{{1.69}{12}}
\newlabel{eq:38}{{1.70}{12}}
\@writefile{toc}{\contentsline {subsubsection}{Sampling $\alpha $ and $\gamma $}{12}}
\newlabel{sec:sampling-alpha}{{1.3.1}{12}}
\newlabel{eq:42}{{1.71}{12}}
\newlabel{eq:43}{{1.78}{13}}
\newlabel{eq:8}{{1.79}{13}}
\newlabel{eq:44}{{1.80}{13}}
\newlabel{eq:9}{{1.81}{13}}
\newlabel{eq:10}{{1.83}{14}}
\newlabel{eq:11}{{1.84}{14}}
\newlabel{eq:18}{{1.85}{14}}
\@writefile{toc}{\contentsline {subsubsection}{Summary}{14}}
\newlabel{eq:100}{{1.86}{14}}
\newlabel{eq:46}{{1.87}{14}}
\newlabel{eq:64}{{1.88}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Sampling $\mathbf  {z}$ and the auxiliary variables}{14}}
\newlabel{sec:sampling-z_t}{{1.3.2}{14}}
\citation{johnson2013bayesian}
\newlabel{eq:19}{{1.92}{15}}
\newlabel{eq:48}{{1.94}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Sampling state and emission parameters}{15}}
\newlabel{sec:sampling-eta}{{1.3.3}{15}}
\newlabel{eq:65}{{1.99}{15}}
\@writefile{toc}{\contentsline {subsubsection}{Sampling $\bm  {\theta }$}{16}}
\newlabel{sec:sampling-eta}{{1.3.3}{16}}
\newlabel{eq:39}{{1.101}{16}}
\newlabel{eq:68}{{1.102}{16}}
\newlabel{eq:70}{{1.103}{16}}
\newlabel{eq:71}{{1.104}{16}}
\newlabel{eq:72}{{1.105}{17}}
\newlabel{eq:77}{{1.106}{17}}
\newlabel{eq:74}{{1.109}{17}}
\newlabel{eq:73}{{1.110}{17}}
\newlabel{eq:76}{{1.111}{17}}
\newlabel{eq:91}{{1.112}{17}}
\citation{gilks1992adaptive}
\@writefile{toc}{\contentsline {subsubsection}{Sampling $\bm  {\mu }$}{18}}
\newlabel{sec:sampling-bmu}{{1.3.3}{18}}
\newlabel{eq:92}{{1.113}{18}}
\newlabel{eq:93}{{1.114}{18}}
\@writefile{toc}{\contentsline {subsubsection}{Sampling $\lambda $}{18}}
\newlabel{sec:sampling-lambda}{{1.3.3}{18}}
\newlabel{eq:88}{{1.115}{18}}
\newlabel{eq:88}{{1.116}{18}}
\newlabel{eq:90}{{1.117}{18}}
\newlabel{eq:94}{{1.118}{18}}
\@writefile{toc}{\contentsline {subsubsection}{Sampling $\mathbf  {W}$}{19}}
\newlabel{eq:78}{{1.120}{19}}
\newlabel{eq:79}{{1.121}{19}}
\newlabel{eq:80}{{1.122}{19}}
\newlabel{eq:83}{{1.123}{19}}
\newlabel{eq:84}{{1.124}{19}}
\newlabel{eq:81}{{1.125}{19}}
\newlabel{eq:85}{{1.126}{19}}
\newlabel{eq:82}{{1.127}{20}}
\@writefile{toc}{\contentsline {subsubsection}{Summary}{20}}
\newlabel{sec:summary}{{1.3.3}{20}}
\newlabel{eq:102}{{1.133}{20}}
\newlabel{eq:101}{{1.134}{21}}
\citation{collins1997three,collins2003head}
\citation{chen1999empirical}
\citation{collins2003head}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Two Dirichlet Process Models of Probabilistic Context-Rich Grammars}{22}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{eq:3}{{2.1}{23}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Representation of Captions}{24}}
\citation{collins2003head}
\citation{collins2003head}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Elaboration Trees: $\Psi $}{25}}
\citation{collins2003head}
\citation{marcus1993building}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces A semantic tree that might generate the sentence ``A white lamp on a table is in front of a green bed.''. Nodes prefixed by ``H'' are the ``head'' child of the parent; nodes prefixed by ``T'' are the ``target'' (the primary argument), and nodes prefixed by ``B'' are the ``base'' (the secondary argument). Nodes prefixed by ``A'' are attributes.\relax }}{26}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:elaboration-tree}{{2.1}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Syntactic Trees: $\Lambda $}{26}}
\citation{collins2003head}
\citation{collins2003head}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Representation of Context}{27}}
\newlabel{sec:context-representation}{{2.1.3}{27}}
\newlabel{eq:2}{{2.2}{27}}
\citation{collins2003head}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Features included in each event type. The features $l$, $t$ and $w$ denote constituent label, part-of-speech tag, and word, respectively. The $s$ and $sa$ features represent the head and arguments, respectively, of a semantic elaboration node. The $dist$ feature for modifier events is Collins' distance feature, which specifies (a) whether a modifier is on the left or right of the head, (b) whether the modifier is adjacent to the head, and (c) whether there is a verb contained in any constituent between the modifier and the head. Features without subscripts refer to the constituent currently being generated; features with the subscript $p$ refer to the parent constituent, and features with the subscript $h$ refer to the sister head constituent.\relax }}{28}}
\newlabel{tab:event-definitions}{{2.1}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Heuristic Smoothing}{28}}
\newlabel{eq:smoothing-recursion}{{2.3}{28}}
\citation{teh2006hierarchical}
\citation{teh2006hierarchical}
\newlabel{eq:smoothing-base-case}{{2.4}{29}}
\newlabel{eq:lambda-definition}{{2.5}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}An HDP Model of Context-Conditional Event Distributions}{29}}
\newlabel{sec:hdp-smoothing}{{2.3}{29}}
\newlabel{eq:3}{{2.6}{29}}
\citation{teh2006hierarchical}
\citation{teh2006hierarchical}
\newlabel{eq:4}{{2.7}{30}}
\newlabel{eq:4}{{2.8}{30}}
\citation{antoniak1974mixtures}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Heuristic Smoothing as an Approximation to the HDP Prior}{31}}
\newlabel{eq:alpha-T-likelihood}{{2.9}{31}}
\newlabel{eq:w-definition}{{2.10}{31}}
\newlabel{eq:alpha-given-w-and-T}{{2.13}{32}}
\newlabel{eq:w-definition}{{2.15}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Posterior Estimation of Event Distributions in the HDP Model}{33}}
\citation{blei2011distance}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}A Similarity-Based Dependency Structure for Context-Conditional Event Distributions}{34}}
\newlabel{eq:exponential-similarity}{{2.19}{35}}
\newlabel{eq:weighted-similarity}{{2.20}{35}}
\bibstyle{apalike}
\bibdata{../../../manuscripts/sac/bib/scenes_and_captions}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Posterior Estimation of Event Distributions in the Similarity-Based Model}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces A parse tree for the example sentence. Each node has the form LABEL(TAG,Word). Asterisks indicate nodes that are the head child of their parent. All other nodes are ``modifiers''. Each nonterminal node is the start of a ``spike'', which is obtained by iteratively descending to the head child.\relax }}{37}}
\newlabel{fig:parse-tree}{{2.2}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces A parse tree for the example sentence augmented with semantic information. Nodes have the form LABEL(TAG, WORD, PREDICATE(args))\relax }}{38}}
\newlabel{fig:augmented-tree}{{2.3}{38}}
\bibcite{antoniak1974mixtures}{{1}{1974}{{Antoniak}}{{}}}
\bibcite{beal2001infinite}{{2}{2001}{{Beal et~al.}}{{}}}
\bibcite{blei2011distance}{{3}{2011}{{Blei and Frazier}}{{}}}
\bibcite{chen1999empirical}{{4}{1999}{{Chen and Goodman}}{{}}}
\bibcite{collins1997three}{{5}{1997}{{Collins}}{{}}}
\bibcite{collins2003head}{{6}{2003}{{Collins}}{{}}}
\bibcite{ferguson1973bayesian}{{7}{1973}{{Ferguson}}{{}}}
\bibcite{gilks1992adaptive}{{8}{1992}{{Gilks and Wild}}{{}}}
\bibcite{johnson2013bayesian}{{9}{2013}{{Johnson and Willsky}}{{}}}
\bibcite{marcus1993building}{{10}{1993}{{Marcus et~al.}}{{}}}
\bibcite{paisley2011discrete}{{11}{2011}{{Paisley et~al.}}{{}}}
\bibcite{rasmussen2000infinite}{{12}{2000}{{Rasmussen}}{{}}}
\bibcite{teh2006hierarchical}{{13}{2006}{{Teh et~al.}}{{}}}
