\contentsline {chapter}{List of Tables}{9}
\contentsline {chapter}{List of Figures}{10}
\contentsline {chapter}{Abstract}{11}
\contentsline {chapter}{\chapterline {1} \MakeUppercase {Statistical Models and Model Selection} }{13}
\contentsline {section}{\numberline {1.1}Introduction}{13}
\contentsline {subsection}{\numberline {1.1.1}An overview of the dissertation}{15}
\contentsline {section}{\numberline {1.2}Model Selection}{16}
\contentsline {subsection}{\numberline {1.2.1}The Likelihood Function and the Conservation of Explanatory Power}{16}
\contentsline {subsection}{\numberline {1.2.2}The Bias-Variance Tradeoff}{18}
\contentsline {subsection}{\numberline {1.2.3}Example: Polynomial Regression}{19}
\contentsline {subsection}{\numberline {1.2.4}Balancing Fit and Complexity: Bayesian Occam's Razor}{21}
\contentsline {section}{\numberline {1.3}Clustering via a Mixture of Gaussians Model}{23}
\contentsline {section}{\numberline {1.4}Clustering Sequential Data: The Hidden Markov Model}{24}
\contentsline {section}{\numberline {1.5}Model Selection in HMMs and the Mixture of Gaussians Model}{26}
\contentsline {chapter}{\chapterline {2} \MakeUppercase {Bayesian Nonparametric Models and the Infinite Hidden Markov Model} }{28}
\contentsline {section}{\numberline {2.1}Parametric Vs. Nonparametric Models}{28}
\contentsline {section}{\numberline {2.2}The Dirichlet Process}{29}
\contentsline {subsection}{\numberline {2.2.1}The Normalized Gamma Process representation of the DP}{31}
\contentsline {subsection}{\numberline {2.2.2}The Stick-Breaking Process construction of the DP}{32}
\contentsline {subsection}{\numberline {2.2.3}The Chinese Restaurant Process}{32}
\contentsline {subsection}{\numberline {2.2.4}The Dirichlet Process Mixture Model}{33}
\contentsline {subsection}{\numberline {2.2.5}Two Gibbs Samplers for DP Mixture Models}{34}
\contentsline {paragraph}{Method 1: A Collapsed Sampler Based on the CRP}{35}
\contentsline {paragraph}{Method 2: An uncollapsed sampler based on the Stick-Breaking Process}{36}
\contentsline {section}{\numberline {2.3}An Infinite State HMM}{37}
\contentsline {subsection}{\numberline {2.3.1}The Hierarchical Dirichlet Process}{38}
\contentsline {subsection}{\numberline {2.3.2}The HDP-HMM}{38}
\contentsline {subsection}{\numberline {2.3.3}A Stick-Breaking Representation of the Aggregate Weights in an HDP}{40}
\contentsline {subsection}{\numberline {2.3.4}A Normalized Gamma Process Representation of the Weights in the HDP}{41}
\contentsline {subsection}{\numberline {2.3.5}Adapting the HDP for an Infinite State HMM}{41}
\contentsline {section}{\numberline {2.4}Inference in Finite and Infinite State HMMs}{42}
\contentsline {subsection}{\numberline {2.4.1}The Forward Backward Algorithm}{43}
\contentsline {paragraph}{The Backward Step}{44}
\contentsline {paragraph}{The Forward Step}{44}
\contentsline {subsection}{\numberline {2.4.2}Gibbs Sampling in the HDP-HMM}{45}
\contentsline {subsection}{\numberline {2.4.3}Beam Sampling in the HDP-HMM}{46}
\contentsline {section}{\numberline {2.5}Local Transitions}{49}
\contentsline {chapter}{\chapterline {3}\MakeUppercase {HaMMLeT: An infinite Hidden Markov Model with Local Transitions}}{51}
\contentsline {section}{\numberline {3.1}Transition Dynamics in the HDP-HMM}{52}
\contentsline {section}{\numberline {3.2}An HDP-HMM With Local Transitions}{54}
\contentsline {paragraph}{Notational Conventions}{54}
\contentsline {subsection}{\numberline {3.2.1}A Normalized Gamma Process representation of the HDP-HMM}{55}
\contentsline {subsection}{\numberline {3.2.2}Promoting ``Local'' Transitions}{56}
\contentsline {section}{\numberline {3.3}The HDP-HMM-LT as a continuous-time Markov Jump Process with ``failed'' jumps}{58}
\contentsline {subsection}{\numberline {3.3.1}An HDP-HSMM-LT modification}{61}
\contentsline {subsection}{\numberline {3.3.2}Summary}{63}
\contentsline {section}{\numberline {3.4}MCMC Inference in the ``Failed Jumps'' Representation}{63}
\contentsline {subsection}{\numberline {3.4.1}Sampling $\pi $, $\beta $, $\alpha $ and $\gamma $}{64}
\contentsline {paragraph}{Sampling $\pi $}{65}
\contentsline {paragraph}{Sampling $\beta $}{65}
\contentsline {paragraph}{Sampling $\alpha $ and $\gamma $}{67}
\contentsline {subsubsection}{Summary}{69}
\contentsline {subsection}{\numberline {3.4.2}Sampling $z$ and the auxiliary variables}{69}
\contentsline {subsection}{\numberline {3.4.3}Sampling state and emission parameters}{70}
\contentsline {section}{\numberline {3.5}Use Cases}{71}
\contentsline {chapter}{\chapterline {4}\MakeUppercase {Binary Vector States: Speaker Diarization}}{73}
\contentsline {section}{\numberline {4.1}Binary State Vectors}{73}
\contentsline {subsection}{\numberline {4.1.1}Additional Inference Steps}{74}
\contentsline {paragraph}{Sampling $\theta $}{74}
\contentsline {paragraph}{Sampling $\mu $}{76}
\contentsline {paragraph}{Sampling $W$ and $\Sigma $}{76}
\contentsline {paragraph}{Sampling $\lambda $}{77}
\contentsline {subsection}{\numberline {4.1.2}Summary}{77}
\contentsline {section}{\numberline {4.2}``Cocktail Party'' Data}{79}
\contentsline {section}{\numberline {4.3}Synthetic Data Without Local Transitions}{81}
\contentsline {chapter}{\chapterline {5}\MakeUppercase {Categorical Vector States: Power Disaggregation}}{84}
\contentsline {section}{\numberline {5.1}Generalizing to Categorical-Valued $\theta $}{84}
\contentsline {section}{\numberline {5.2}Priors and Representations in the Categorical State Variant}{85}
\contentsline {section}{\numberline {5.3}Adapting Posterior Inference for Categorical State Vectors}{86}
\contentsline {subsubsection}{Sampling $\theta $}{86}
\contentsline {paragraph}{Sampling $W$}{87}
\contentsline {paragraph}{Sampling $\lambda $}{87}
\contentsline {section}{\numberline {5.4}Power Disaggregation}{87}
\contentsline {chapter}{\chapterline {6}\MakeUppercase {Separate Similarities and Emissions: Learning Tonal Grammar in Music}}{90}
\contentsline {section}{\numberline {6.1}Separable Similarity and Emissions}{90}
\contentsline {section}{\numberline {6.2}A Hamlitonian Monte Carlo step to sample $\eta $}{90}
\contentsline {section}{\numberline {6.3}Synthetic Data from an HMM with a Nearly Block Diagonal Transition Matrix}{93}
\contentsline {subsection}{\numberline {6.3.1}Data-generation}{93}
\contentsline {subsection}{\numberline {6.3.2}Results}{94}
\contentsline {section}{\numberline {6.4}Discovering Chord Equivalence Classes in Tonal Music}{94}
\contentsline {chapter}{\chapterline {7}\MakeUppercase {Conclusions and Future Work}}{95}
\contentsline {chapter}{References}{96}
